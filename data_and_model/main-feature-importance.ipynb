{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_absolute_error, accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#parameters setting\n",
    "\n",
    "#Define the path to your datafolder below\n",
    "your_datapath = ''\n",
    "\n",
    "#Define search space for number of trees in random forest and depth of trees\n",
    "num_trees_min = 8\n",
    "num_trees_max = 9\n",
    "\n",
    "depth_min = 4\n",
    "depth_max = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-126-73eb310316a3>, line 25)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-126-73eb310316a3>\"\u001b[1;36m, line \u001b[1;32m25\u001b[0m\n\u001b[1;33m    '''conflict_df.fillna(0,inplace=True)\u001b[0m\n\u001b[1;37m       ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "'''datapath = ''\n",
    "district_name = 'Baidoa'\n",
    "\n",
    "prevalence_df = pd.read_csv(datapath + 'prevalence_estimates.csv', parse_dates=['date'])\n",
    "ipc_df = pd.read_csv(datapath + 'ipc2.csv', parse_dates=['date'])\n",
    "risk_df = pd.read_csv(datapath + 'FSNAU_riskfactors.csv', parse_dates=['date'])\n",
    "production_df = pd.read_csv(datapath + 'production.csv', parse_dates=['date'])\n",
    "    \n",
    "admissions_df = pd.read_csv(datapath + 'admissions.csv', parse_dates=['date'])\n",
    "conflict_df = pd.read_csv(datapath + 'conflict.csv', parse_dates=['date'])\n",
    "\n",
    "\n",
    "#date only\n",
    "covid_df = pd.read_csv(datapath + 'covid.csv', parse_dates=['date'])\n",
    "    \n",
    "    \n",
    "#Select data for specific district\n",
    "prevalence_df = prevalence_df[prevalence_df['district']==district_name]\n",
    "ipc_df = ipc_df[ipc_df['district']==district_name]\n",
    "risk_df = risk_df[risk_df['district']==district_name]\n",
    "production_df = production_df[production_df['district']==district_name]\n",
    "admissions_df = admissions_df[admissions_df['district']==district_name]\n",
    "conflict_df = conflict_df[conflict_df['district']==district_name]\n",
    "    \n",
    "'''conflict_df.fillna(0,inplace=True)\n",
    "production_df.fillna(0,inplace=True)'''\n",
    "\n",
    "#name mismatch\n",
    "if len(conflict_df)==0:\n",
    "    print('error1 on ' + district_name)\n",
    "if len(admissions_df)==0:\n",
    "    print('error2 on ' + district_name)\n",
    "if len(production_df)==0:\n",
    "    print('error3 on ' + district_name)\n",
    "    \n",
    "#GroupBy \"key\", 6M = 6 months, x.replace(day=1) = the first day of that month\n",
    "risk_df = risk_df.groupby(pd.Grouper(key='date', freq='6M')).mean() \n",
    "risk_df = risk_df.reset_index()\n",
    "risk_df['date'] = risk_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "covid_df = covid_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "covid_df = covid_df.reset_index()\n",
    "covid_df['date'] = covid_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "conflict_df = conflict_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "conflict_df = conflict_df.reset_index()\n",
    "conflict_df['date'] = conflict_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "admissions_df = admissions_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "admissions_df = admissions_df.reset_index()\n",
    "admissions_df['date'] = admissions_df['date'].apply(lambda x : x.replace(day=1))\n",
    "\n",
    "production_df = production_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "production_df = production_df.reset_index()\n",
    "production_df['date'] = production_df['date'].apply(lambda x : x.replace(day=1))\n",
    "\n",
    "#production_df['cropdiv'] = production_df.count(axis=1)\n",
    "    \n",
    "#Sort dataframes on date\n",
    "prevalence_df.sort_values('date', inplace=True)\n",
    "covid_df.sort_values('date', inplace=True)\n",
    "ipc_df.sort_values('date', inplace=True)\n",
    "risk_df.sort_values('date', inplace=True)\n",
    "production_df.sort_values('date', inplace=True)\n",
    "admissions_df.sort_values('date', inplace=True)\n",
    "conflict_df.sort_values('date', inplace=True)\n",
    "    \n",
    "\n",
    "#Merge dataframes, only joining on current or previous dates as to prevent data leakage\n",
    "df = pd.merge_asof(left=prevalence_df, right=ipc_df, direction='backward', on='date')\n",
    "df = pd.merge_asof(left=df, right=production_df, direction='backward', on='date')\n",
    "df = pd.merge_asof(left=df, right=risk_df, direction='backward', on='date')\n",
    "df = pd.merge_asof(left=df, right=covid_df, direction='backward', on='date')\n",
    "    \n",
    "df = pd.merge_asof(left=df, right=admissions_df, direction='backward', on='date')\n",
    "df = pd.merge_asof(left=df, right=conflict_df, direction='backward', on='date')\n",
    "    \n",
    "    \n",
    "#Calculate prevalence 6lag\n",
    "df['prevalence_6lag'] = df['GAM Prevalence'].shift(1)\n",
    "df['next_prevalence'] = df['GAM Prevalence'].shift(-1)\n",
    "\n",
    "df.rename(columns={\"GAM Prevalence\": \"prevalence\", \"new_cases\": \"covid\", \"ndvi_score\": \"ndvi\", \"phase3plus_perc\": \"ipc\", \"total population\": \"population\"}, inplace = True)\n",
    "    \n",
    "    \n",
    "#Add month column\n",
    "df['month'] = df['date'].dt.month\n",
    "    \n",
    "#Add target variable: increase for next month prevalence (boolean)\n",
    "increase = [False if x[1]<x[0] else True for x in list(zip(df['prevalence'], df['prevalence'][1:]))]\n",
    "increase.append(False)\n",
    "df['increase'] = increase\n",
    "df.iloc[-1, df.columns.get_loc('increase')] = np.nan #No info on next month\n",
    "    \n",
    "#Add target variable: increase for next month prevalence (boolean)\n",
    "increase_numeric = [x[1] - x[0] for x in list(zip(df['prevalence'], df['prevalence'][1:]))]\n",
    "increase_numeric.append(0)\n",
    "df['increase_numeric'] = increase_numeric\n",
    "df.iloc[-1, df.columns.get_loc('increase_numeric')] = np.nan #No info on next month\n",
    "    \n",
    "df.loc[(df.date < pd.to_datetime('2020-03-01')), 'covid'] = 0\n",
    "df'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that creates a pandas dataframe for a single district with columns for the baseline model with semiyearly entries\n",
    "def make_district_df_semiyearly(datapath, district_name):\n",
    "    \"\"\"\n",
    "    Function that creates a pandas dataframe for a single district with columns for the baseline model with semiyearly entries\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapath : string\n",
    "        Path to the datafolder\n",
    "    district_name : string\n",
    "        Name of the district\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "    \"\"\"\n",
    "    #print(district_name)\n",
    "    \n",
    "\t#Read all relevant datasets\n",
    "    #date and district \n",
    "    prevalence_df = pd.read_csv(datapath + 'prevalence_estimates.csv', parse_dates=['date'])\n",
    "    ipc_df = pd.read_csv(datapath + 'ipc2.csv', parse_dates=['date'])\n",
    "    risk_df = pd.read_csv(datapath + 'FSNAU_riskfactors.csv', parse_dates=['date'])\n",
    "    production_df = pd.read_csv(datapath + 'production.csv', parse_dates=['date'])\n",
    "    \n",
    "    admissions_df = pd.read_csv(datapath + 'admissions.csv', parse_dates=['date'])\n",
    "    conflict_df = pd.read_csv(datapath + 'conflict.csv', parse_dates=['date'])\n",
    "    \n",
    "    #date only\n",
    "    covid_df = pd.read_csv(datapath + 'covid.csv', parse_dates=['date'])\n",
    "    \n",
    "    \n",
    "    #Select data for specific district\n",
    "    prevalence_df = prevalence_df[prevalence_df['district']==district_name]\n",
    "    ipc_df = ipc_df[ipc_df['district']==district_name]\n",
    "    risk_df = risk_df[risk_df['district']==district_name]\n",
    "    production_df = production_df[production_df['district']==district_name]\n",
    "    admissions_df = admissions_df[admissions_df['district']==district_name]\n",
    "    conflict_df = conflict_df[conflict_df['district']==district_name]\n",
    "    \n",
    "    '''conflict_df.fillna(0,inplace=True)\n",
    "    production_df.fillna(0,inplace=True)'''\n",
    "    \n",
    "\n",
    "    '''#name mismatch\n",
    "    if len(conflict_df)==0:\n",
    "        print('error1 on ' + district_name)\n",
    "    if len(admissions_df)==0:\n",
    "        print('error2 on ' + district_name)\n",
    "    if len(production_df)==0:\n",
    "        print('error3 on ' + district_name)'''\n",
    "        \n",
    "    #GroupBy \"key\", 6M = 6 months, x.replace(day=1) = the first day of that month\n",
    "    risk_df = risk_df.groupby(pd.Grouper(key='date', freq='6M')).mean() \n",
    "    risk_df = risk_df.reset_index()\n",
    "    risk_df['date'] = risk_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "    covid_df = covid_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "    covid_df = covid_df.reset_index()\n",
    "    covid_df['date'] = covid_df['date'].apply(lambda x : x.replace(day=1))\n",
    "\n",
    "    conflict_df = conflict_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "    conflict_df = conflict_df.reset_index()\n",
    "    conflict_df['date'] = conflict_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "    admissions_df = admissions_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "    admissions_df = admissions_df.reset_index()\n",
    "    admissions_df['date'] = admissions_df['date'].apply(lambda x : x.replace(day=1))\n",
    "\n",
    "    production_df = production_df.groupby(pd.Grouper(key='date', freq='6M')).sum()\n",
    "    production_df = production_df.reset_index()\n",
    "    production_df['date'] = production_df['date'].apply(lambda x : x.replace(day=1))\n",
    "    \n",
    "    #production_df['cropdiv'] = production_df.count(axis=1)\n",
    "    \n",
    "    #Sort dataframes on date\n",
    "    prevalence_df.sort_values('date', inplace=True)\n",
    "    covid_df.sort_values('date', inplace=True)\n",
    "    ipc_df.sort_values('date', inplace=True)\n",
    "    risk_df.sort_values('date', inplace=True)\n",
    "    production_df.sort_values('date', inplace=True)\n",
    "    admissions_df.sort_values('date', inplace=True)\n",
    "    conflict_df.sort_values('date', inplace=True)\n",
    "    \n",
    "\n",
    "    #Merge dataframes, only joining on current or previous dates as to prevent data leakage\n",
    "    df = pd.merge_asof(left=prevalence_df, right=ipc_df, direction='backward', on='date')\n",
    "    df = pd.merge_asof(left=df, right=production_df, direction='backward', on='date')\n",
    "    df = pd.merge_asof(left=df, right=risk_df, direction='backward', on='date')\n",
    "    df = pd.merge_asof(left=df, right=covid_df, direction='backward', on='date')\n",
    "    \n",
    "    df = pd.merge_asof(left=df, right=admissions_df, direction='backward', on='date')\n",
    "    df = pd.merge_asof(left=df, right=conflict_df, direction='backward', on='date')\n",
    "    \n",
    "    \n",
    "    #Calculate prevalence 6lag\n",
    "    df['prevalence_6lag'] = df['GAM Prevalence'].shift(1)\n",
    "    df['next_prevalence'] = df['GAM Prevalence'].shift(-1)\n",
    "    \n",
    "    '''    \n",
    "    #Select needed columns\n",
    "    df = df[['date', 'district', 'GAM Prevalence', 'next_prevalence', 'prevalence_6lag', 'new_cases', 'ndvi_score', 'phase3plus_perc', 'cropdiv', 'total population']]\n",
    "    df.columns = ['date', 'district', 'prevalence', 'next_prevalence', 'prevalence_6lag', 'covid', 'ndvi', 'ipc', 'cropdiv', 'population']\n",
    "    '''\n",
    "    df.rename(columns={\"GAM Prevalence\": \"prevalence\", \"new_cases\": \"covid\", \"ndvi_score\": \"ndvi\", \"phase3plus_perc\": \"ipc\", \"total population\": \"population\"}, inplace = True)\n",
    "    \n",
    "    #Add month column\n",
    "    df['month'] = df['date'].dt.month\n",
    "    \n",
    "    #Add target variable: increase for next month prevalence (boolean)\n",
    "    increase = [False if x[1]<x[0] else True for x in list(zip(df['prevalence'], df['prevalence'][1:]))]\n",
    "    increase.append(False)\n",
    "    df['increase'] = increase\n",
    "    df.iloc[-1, df.columns.get_loc('increase')] = np.nan #No info on next month\n",
    "    \n",
    "    #Add target variable: increase for next month prevalence (boolean)\n",
    "    increase_numeric = [x[1] - x[0] for x in list(zip(df['prevalence'], df['prevalence'][1:]))]\n",
    "    increase_numeric.append(0)\n",
    "    df['increase_numeric'] = increase_numeric\n",
    "    df.iloc[-1, df.columns.get_loc('increase_numeric')] = np.nan #No info on next month\n",
    "    \n",
    "    df.loc[(df.date < pd.to_datetime('2020-03-01')), 'covid'] = 0\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that combines the semiyearly dataset (from the function make_district_df_semiyearly) of all districts\n",
    "def make_combined_df_semiyearly(datapath):\n",
    "    \"\"\"\n",
    "    Function that creates a pandas dataframe for all districts with columns for the baseline model with semiyearly entries\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    datapath : string\n",
    "        Path to the datafolder\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    df : pandas dataframe\n",
    "    \"\"\"\n",
    "\n",
    "    prevdf = pd.read_csv(datapath + 'prevalence_estimates.csv', parse_dates=['date'])\n",
    "    districts = prevdf['district'].unique()\n",
    "    \n",
    "    df_list = []\n",
    "    for district in districts:\n",
    "        district_df = make_district_df_semiyearly(datapath, district)\n",
    "        district_df['district'] = district\n",
    "        df_list.append(district_df)\n",
    "        \n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    df['district_encoded'] = df['district'].astype('category').cat.codes\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function that returns every possible subset (except the empty set) of the input list l\n",
    "def subsets (l):\n",
    "    subset_list = []\n",
    "    for i in range(len(l) + 1):\n",
    "        for j in range(i):\n",
    "            subset_list.append(l[j: i])\n",
    "    return subset_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>date</th>\n",
       "      <th>district_x</th>\n",
       "      <th>population</th>\n",
       "      <th>Under-Five Population</th>\n",
       "      <th>GAM</th>\n",
       "      <th>MAM</th>\n",
       "      <th>SAM</th>\n",
       "      <th>prevalence</th>\n",
       "      <th>SAM Prevalence</th>\n",
       "      <th>...</th>\n",
       "      <th>n_strategicdev</th>\n",
       "      <th>n_violcivilians</th>\n",
       "      <th>n_conflict_total</th>\n",
       "      <th>prevalence_6lag</th>\n",
       "      <th>next_prevalence</th>\n",
       "      <th>month</th>\n",
       "      <th>increase</th>\n",
       "      <th>increase_numeric</th>\n",
       "      <th>district</th>\n",
       "      <th>district_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>605</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>Adan Yabaal</td>\n",
       "      <td>65262.960</td>\n",
       "      <td>13052.592</td>\n",
       "      <td>4819.016966</td>\n",
       "      <td>3733.041312</td>\n",
       "      <td>1085.975654</td>\n",
       "      <td>0.369200</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3510</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.018200</td>\n",
       "      <td>Adan Yabaal</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>646</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>Iskushuban</td>\n",
       "      <td>82588.860</td>\n",
       "      <td>16517.772</td>\n",
       "      <td>6699.608323</td>\n",
       "      <td>5583.006936</td>\n",
       "      <td>1116.601387</td>\n",
       "      <td>0.405600</td>\n",
       "      <td>0.067600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.3432</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.062400</td>\n",
       "      <td>Iskushuban</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>645</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>Hobyo</td>\n",
       "      <td>285434.370</td>\n",
       "      <td>57086.874</td>\n",
       "      <td>27013.508777</td>\n",
       "      <td>21670.177370</td>\n",
       "      <td>5343.331406</td>\n",
       "      <td>0.473200</td>\n",
       "      <td>0.093600</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.4004</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.072800</td>\n",
       "      <td>Hobyo</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>644</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>Hargeysa</td>\n",
       "      <td>1071923.705</td>\n",
       "      <td>214384.741</td>\n",
       "      <td>73445.882458</td>\n",
       "      <td>55654.832007</td>\n",
       "      <td>17791.050451</td>\n",
       "      <td>0.342589</td>\n",
       "      <td>0.082987</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.144989</td>\n",
       "      <td>Hargeysa</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>643</td>\n",
       "      <td>2017-07-01</td>\n",
       "      <td>Gebiley</td>\n",
       "      <td>146038.500</td>\n",
       "      <td>29207.700</td>\n",
       "      <td>9872.202600</td>\n",
       "      <td>7442.121960</td>\n",
       "      <td>2430.080640</td>\n",
       "      <td>0.338000</td>\n",
       "      <td>0.083200</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>7</td>\n",
       "      <td>False</td>\n",
       "      <td>-0.140400</td>\n",
       "      <td>Gebiley</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>672</th>\n",
       "      <td>42</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>Hargeysa</td>\n",
       "      <td>0.000</td>\n",
       "      <td>176920.000</td>\n",
       "      <td>47350.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>8550.000000</td>\n",
       "      <td>0.267635</td>\n",
       "      <td>0.048327</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.196585</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Hargeysa</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>673</th>\n",
       "      <td>43</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>Hobyo</td>\n",
       "      <td>0.000</td>\n",
       "      <td>31703.200</td>\n",
       "      <td>9040.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1030.000000</td>\n",
       "      <td>0.285145</td>\n",
       "      <td>0.032489</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.284180</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Hobyo</td>\n",
       "      <td>53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>674</th>\n",
       "      <td>68</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>Waajid</td>\n",
       "      <td>0.000</td>\n",
       "      <td>15159.400</td>\n",
       "      <td>6820.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1490.000000</td>\n",
       "      <td>0.449886</td>\n",
       "      <td>0.098289</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.493352</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Waajid</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>675</th>\n",
       "      <td>45</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>Jalalaqsi</td>\n",
       "      <td>0.000</td>\n",
       "      <td>10831.400</td>\n",
       "      <td>4420.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>840.000000</td>\n",
       "      <td>0.408073</td>\n",
       "      <td>0.077552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.194715</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Jalalaqsi</td>\n",
       "      <td>55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>676</th>\n",
       "      <td>39</td>\n",
       "      <td>2021-07-01</td>\n",
       "      <td>Garbahaarey</td>\n",
       "      <td>0.000</td>\n",
       "      <td>25083.400</td>\n",
       "      <td>8210.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1000.000000</td>\n",
       "      <td>0.327308</td>\n",
       "      <td>0.039867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.363730</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Garbahaarey</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows × 83 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Unnamed: 0       date   district_x   population  Under-Five Population  \\\n",
       "0           605 2017-07-01  Adan Yabaal    65262.960              13052.592   \n",
       "1           646 2017-07-01   Iskushuban    82588.860              16517.772   \n",
       "2           645 2017-07-01        Hobyo   285434.370              57086.874   \n",
       "3           644 2017-07-01     Hargeysa  1071923.705             214384.741   \n",
       "4           643 2017-07-01      Gebiley   146038.500              29207.700   \n",
       "..          ...        ...          ...          ...                    ...   \n",
       "672          42 2021-07-01     Hargeysa        0.000             176920.000   \n",
       "673          43 2021-07-01        Hobyo        0.000              31703.200   \n",
       "674          68 2021-07-01       Waajid        0.000              15159.400   \n",
       "675          45 2021-07-01    Jalalaqsi        0.000              10831.400   \n",
       "676          39 2021-07-01  Garbahaarey        0.000              25083.400   \n",
       "\n",
       "              GAM           MAM           SAM  prevalence  SAM Prevalence  \\\n",
       "0     4819.016966   3733.041312   1085.975654    0.369200        0.083200   \n",
       "1     6699.608323   5583.006936   1116.601387    0.405600        0.067600   \n",
       "2    27013.508777  21670.177370   5343.331406    0.473200        0.093600   \n",
       "3    73445.882458  55654.832007  17791.050451    0.342589        0.082987   \n",
       "4     9872.202600   7442.121960   2430.080640    0.338000        0.083200   \n",
       "..            ...           ...           ...         ...             ...   \n",
       "672  47350.000000      0.000000   8550.000000    0.267635        0.048327   \n",
       "673   9040.000000      0.000000   1030.000000    0.285145        0.032489   \n",
       "674   6820.000000      0.000000   1490.000000    0.449886        0.098289   \n",
       "675   4420.000000      0.000000    840.000000    0.408073        0.077552   \n",
       "676   8210.000000      0.000000   1000.000000    0.327308        0.039867   \n",
       "\n",
       "     ...  n_strategicdev n_violcivilians n_conflict_total  prevalence_6lag  \\\n",
       "0    ...             0.0             0.0              0.0         0.000000   \n",
       "1    ...             0.0             1.0              3.0         0.000000   \n",
       "2    ...             0.0             6.0             11.0         0.000000   \n",
       "3    ...             3.0             4.0             19.0         0.000000   \n",
       "4    ...             1.0             0.0              3.0         0.000000   \n",
       "..   ...             ...             ...              ...              ...   \n",
       "672  ...             0.0             0.0              1.0         0.196585   \n",
       "673  ...             2.0             2.0             19.0         0.284180   \n",
       "674  ...             0.0             4.0             15.0         0.493352   \n",
       "675  ...             0.0             1.0             20.0         0.194715   \n",
       "676  ...             0.0             5.0             17.0         0.363730   \n",
       "\n",
       "     next_prevalence  month  increase  increase_numeric     district  \\\n",
       "0             0.3510      7     False         -0.018200  Adan Yabaal   \n",
       "1             0.3432      7     False         -0.062400   Iskushuban   \n",
       "2             0.4004      7     False         -0.072800        Hobyo   \n",
       "3             0.1976      7     False         -0.144989     Hargeysa   \n",
       "4             0.1976      7     False         -0.140400      Gebiley   \n",
       "..               ...    ...       ...               ...          ...   \n",
       "672           0.0000      7         0          0.000000     Hargeysa   \n",
       "673           0.0000      7         0          0.000000        Hobyo   \n",
       "674           0.0000      7         0          0.000000       Waajid   \n",
       "675           0.0000      7         0          0.000000    Jalalaqsi   \n",
       "676           0.0000      7         0          0.000000  Garbahaarey   \n",
       "\n",
       "     district_encoded  \n",
       "0                   2  \n",
       "1                  54  \n",
       "2                  53  \n",
       "3                  52  \n",
       "4                  51  \n",
       "..                ...  \n",
       "672                52  \n",
       "673                53  \n",
       "674                81  \n",
       "675                55  \n",
       "676                49  \n",
       "\n",
       "[649 rows x 83 columns]"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''------------SECTION DATAFRAME CREATION--------------'''\n",
    "#Create the dataframe for all districts\n",
    "df = make_combined_df_semiyearly(your_datapath)\n",
    "\n",
    "'''#Drop every row with missing values\n",
    "df.dropna(inplace=True)'''\n",
    "df.fillna(0,inplace=True)\n",
    "\n",
    "#Sort dataframe on date and reset the index\n",
    "df.sort_values('date', inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "\n",
    "#Drop disctricts with less than 7 observations: 'Burco', 'Saakow', 'Rab Dhuure', 'Baydhaba', 'Afmadow'\n",
    "df.drop(df[df['district'].isin(['Burco', 'Saakow', 'Rab Dhuure', 'Baydhaba', 'Afmadow'])].index, inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------SECTION RANDOM FOREST CROSS VALIDATION--------------'''\n",
    "#WARNING: this process can take some time, since there are a lot of hyperparameters to investigate. The search space can be manually reduced to speed up the process.\n",
    "\n",
    "#Create empty list to store model scores\n",
    "parameter_scores = []\n",
    "\n",
    "#Define target and explanatory variables\n",
    "#X = df.drop(columns = ['increase', 'increase_numeric', 'date', 'district', 'prevalence', 'next_prevalence']) #Note that these columns are dropped, the remaining columns are used as explanatory variables\n",
    "y = df['next_prevalence'].values\n",
    "X = pd.get_dummies(df)\n",
    "X.drop(['date', 'Unnamed: 0'], axis = 1, inplace=True)\n",
    "\n",
    "for num_trees in range(num_trees_min, num_trees_max):\n",
    "    \n",
    "    for depth in range(depth_min, depth_max):\n",
    "        \n",
    "        #Investigate every subset of explanatory variables\n",
    "        for features in subsets(X.columns):\n",
    "        \n",
    "            #First CV split. The 99 refers to the first 3 observations for the 33 districts in the data.\n",
    "            Xtrain = X[:99][features].copy().values\n",
    "            ytrain = y[:99]\n",
    "            Xtest = X[99:132][features].copy().values\n",
    "            ytest = y[99:132]\n",
    "\n",
    "            #Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            #Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            #Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            #Calculate mean absolute error\n",
    "            MAE1 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "\n",
    "            #Second CV split. The 132 refers to the first 4 observations for the 33 districts in the data.\n",
    "            Xtrain = X[:132][features].copy().values\n",
    "            ytrain = y[:132]\n",
    "            Xtest = X[132:165][features].copy().values\n",
    "            ytest = y[132:165]\n",
    "\n",
    "            #Create a RandomForestRegressor with the selected hyperparameters and random state 0.\n",
    "            clf = RandomForestRegressor(n_estimators=num_trees, max_depth=depth, random_state=0)\n",
    "\n",
    "            #Fit to the training data\n",
    "            clf.fit(Xtrain, ytrain)\n",
    "\n",
    "            #Make a prediction on the test data\n",
    "            predictions = clf.predict(Xtest)\n",
    "\n",
    "            #Calculate mean absolute error\n",
    "            MAE2 = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "            #Calculate the mean MAE over the two folds\n",
    "            mean_MAE = (MAE1 + MAE2)/2\n",
    "\n",
    "            #Store the mean MAE together with the used hyperparameters in list \n",
    "            parameter_scores.append((mean_MAE, num_trees, depth, features))\n",
    "\n",
    "#Sort the models based on score and retrieve the hyperparameters of the best model\n",
    "parameter_scores.sort(key=lambda x: x[0])\n",
    "best_model_score = parameter_scores[0][0]\n",
    "best_model_trees = parameter_scores[0][1]\n",
    "best_model_depth = parameter_scores[0][2]\n",
    "best_model_columns = list(parameter_scores[0][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''------------SECTION FINAL EVALUATION--------------'''\n",
    "X = df[best_model_columns].values\n",
    "y = df['next_prevalence'].values\n",
    "\n",
    "#If there is only one explanatory variable, the values need to be reshaped for the model\n",
    "if len(best_model_columns) == 1:\n",
    "\tX = X.reshape(-1, 1)\n",
    "\n",
    "#Peform evaluation on full data\n",
    "Xtrain = X[:165]\n",
    "ytrain = y[:165]\n",
    "Xtest = X[165:]\n",
    "ytest = y[165:]\n",
    "\n",
    "clf = RandomForestRegressor(n_estimators=best_model_trees, max_depth=best_model_depth, random_state=0)\n",
    "clf.fit(Xtrain, ytrain)\n",
    "predictions = clf.predict(Xtest)\n",
    "\n",
    "#Calculate MAE\n",
    "MAE = mean_absolute_error(ytest, predictions)\n",
    "\n",
    "#Generate boolean values for increase or decrease in prevalence. 0 if next prevalence is smaller than current prevalence, 1 otherwise.\n",
    "increase           = [0 if x<y else 1 for x in df.iloc[165:]['next_prevalence'] for y in df.iloc[165:]['prevalence']]\n",
    "predicted_increase = [0 if x<y else 1 for x in predictions                      for y in df.iloc[165:]['prevalence']]\n",
    "\n",
    "#Calculate accuracy of predicted boolean increase/decrease\n",
    "acc = accuracy_score(increase, predicted_increase)\n",
    "\n",
    "#Print model parameters\n",
    "print('no. of trees: ' + str(best_model_trees) + '\\nmax_depth: ' + str(best_model_depth) + '\\ncolumns: ' + str(best_model_columns))\n",
    "\n",
    "#Print model scores\n",
    "print(MAE, acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
